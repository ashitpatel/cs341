{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.callbacks import CSVLogger\n",
    "import json\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17520587514943627619\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15771998618\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 16000391501392083131\n",
      "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path1):\n",
    "    temp_docs = []\n",
    "    labels = []\n",
    "    with open(path1) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "    for x in data:\n",
    "        temp_docs.append(x['body'])\n",
    "#         labels.append(keras.utils.to_categorical(np.array(list(x['middle_label'])),num_classes=102))\n",
    "        labels.append((np.array(list(x['middle_label']))))\n",
    "    len1 = len(temp_docs)\n",
    "    print('number of human rights docs is: '+str(len1))\n",
    "    return temp_docs,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of human rights docs is: 55326\n"
     ]
    }
   ],
   "source": [
    "docs,labels = load_data('/home/tigermlt/CS341/github_repo/CS341/data/data_with_middle_layer_and_label.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# docs_train = docs[:45000]\n",
    "# labels_train = labels[:45000]\n",
    "# docs_val = docs[45000:50000]\n",
    "# labels_val = labels[45000:50000]\n",
    "# docs_test = docs[50000:]\n",
    "# labels_test = labels[50000:]\n",
    "# docs = docs[:100]\n",
    "# labels = labels[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The much-awaited debate on how international patent laws affect developing countries' access to medications begins Wednesday, Jun 20, at the World Trade Organisation (WTO), and the countries, corporations and civil society groups involved are putting the final touches on their arguments.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# random shuffle the data\n",
    "c = list(zip(docs, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs, labels = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = list(docs)\n",
    "labels = list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(docs)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# integer encode the documents\n",
    "encoded_docs = t.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15260\n"
     ]
    }
   ],
   "source": [
    "# compute max document length\n",
    "max_val = -1\n",
    "for i in range(len(docs)):\n",
    "    temp_val = len(docs[i])\n",
    "    if temp_val>max_val:\n",
    "        max_val = temp_val\n",
    "print(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pad documents to a max length, compute by calculating the maximum document length\n",
    "# max_length = 15260\n",
    "max_length = 8000\n",
    "# max_length = 1068\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55326\n"
     ]
    }
   ],
   "source": [
    "print(len(padded_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = zeros((vocab_size, 300))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # prepare validation data\n",
    "\n",
    "# # prepare tokenizer\n",
    "# t_val = Tokenizer()\n",
    "# t_val.fit_on_texts(docs_val)\n",
    "# # integer encode the documents\n",
    "# encoded_docs_val = t_val.texts_to_sequences(docs_val)\n",
    "\n",
    "# padded_docs_val = pad_sequences(encoded_docs_val, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    e = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "    model.add(e)\n",
    "    model.add(LSTM(128,dropout = 0.3,return_sequences=True))\n",
    "    model.add(LSTM(128,dropout = 0.3))\n",
    "#     model.add(LSTM(128,dropout = 0.8,))\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def euclidean_distance_loss(y_true, y_pred):\n",
    "#     y_log = K.log(y_pred)\n",
    "#     y_log_2 = K.log(1-y_pred)\n",
    "    \n",
    "#     part1 = -y_true*y_log\n",
    "#     part2 = -(1-y_true)*y_log_2\n",
    "    \n",
    "#     matrix = part1 + part2\n",
    "#     mean_row = K.mean(matrix,axis=1)\n",
    "    \n",
    "#     loss = K.mean(mean_row,axis=0)\n",
    "\n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    diff = K.abs(y_true-y_pred)\n",
    "    correct_num = K.sum(tf.to_int32(K.greater(0.1,diff)))\n",
    "    accuracy = correct_num/16/102\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_logger=CSVLogger('middle_class_v4.csv',append=True,separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 8000, 300)         28578900  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8000, 128)         219648    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 102)               13158     \n",
      "=================================================================\n",
      "Total params: 28,943,290\n",
      "Trainable params: 364,390\n",
      "Non-trainable params: 28,578,900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=Adam(lr=0.01), loss=['binary_crossentropy'], metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55326, 8000)\n"
     ]
    }
   ],
   "source": [
    "print(padded_docs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49793 samples, validate on 5533 samples\n",
      "Epoch 1/3\n",
      "49793/49793 [==============================] - 13641s 274ms/step - loss: 0.1413 - acc: 0.9522 - val_loss: 0.1476 - val_acc: 0.9415\n",
      "Epoch 2/3\n",
      "49793/49793 [==============================] - 13404s 269ms/step - loss: 0.1439 - acc: 0.9520 - val_loss: 0.1346 - val_acc: 0.9529\n",
      "Epoch 3/3\n",
      "49793/49793 [==============================] - 13602s 273ms/step - loss: 0.1351 - acc: 0.9525 - val_loss: 0.1339 - val_acc: 0.9529\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    # fit the model\n",
    "    model.fit(padded_docs, np.array(labels), epochs=3, validation_split = 0.10, batch_size = 128,callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('middle_class_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    pred = model.predict(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pred[0]>0.1)\n",
    "print(labels[0]>0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs_test = docs[15000:16000]\n",
    "labels_test = labels[15000:16000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/tigermlt/CS341/github_repo/CS341/data/10000.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    for x in data:\n",
    "        if x['content'] is not None:\n",
    "            docs_test.append(x['content'])\n",
    "    len1 = len(docs_test)\n",
    "    print('number of human rights docs is: '+str(len1))\n",
    "    labels_test = [1]*len1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# integer encode the documents\n",
    "encoded_docs_test = t.texts_to_sequences(docs_test)\n",
    "# pad documents to a max length, compute by calculating the maximum document length\n",
    "max_length = 20512\n",
    "padded_docs_test = pad_sequences(encoded_docs_test, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "def load_trained_model(weights_path):\n",
    "    model = build_model()\n",
    "    model.load_weights(weights_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_model = load_trained_model('middle_class.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = train_model.predict(padded_docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp = pred[0]>0.1\n",
    "print(temp.astype(int))\n",
    "print(labels_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pred[0]-labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersection(lst1, lst2):\n",
    "    lst3 = [value for value in lst1 if value in lst2]\n",
    "    return lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "thresh = 0.3\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_count = 0\n",
    "for i in range(1000):\n",
    "    temp_pred = pred[i]>thresh\n",
    "    temp_pred = list(temp_pred.astype(int))\n",
    "    temp_actual = labels_test[i]\n",
    "    \n",
    "    temp_pred_index = []\n",
    "    temp_actual_index = []\n",
    "    \n",
    "    for k,v in enumerate(temp_pred):\n",
    "        if v == 1:\n",
    "            temp_pred_index.append(k)\n",
    "    \n",
    "    for k,v in enumerate(temp_actual):\n",
    "        if v == 1:\n",
    "            temp_actual_index.append(k)\n",
    "            \n",
    "    temp_list = intersection(temp_pred_index,temp_actual_index)\n",
    "    \n",
    "    temp_same = len(temp_list)\n",
    "    if (len(temp_pred_index) != 0 and len(temp_actual_index)!=0 ):\n",
    "        total_count +=1\n",
    "        temp_precision = float(temp_same)/len(temp_pred_index)\n",
    "        temp_recall = float(temp_same)/len(temp_actual_index)\n",
    "    \n",
    "    total_precision += temp_precision\n",
    "    total_recall += temp_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(total_precision)\n",
    "print(total_recall)\n",
    "print(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_pred = pred[0]>0.1\n",
    "temp_pred = list(temp_pred.astype(int))\n",
    "temp_actual = labels_test[0]\n",
    "temp1 = []\n",
    "temp2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k,v in enumerate(temp_pred):\n",
    "    if v == 1:\n",
    "        temp1.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k,v in enumerate(temp_actual):\n",
    "    if v == 1:\n",
    "        temp2.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len1 = len(temp2)\n",
    "print(len1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(temp1)\n",
    "print(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp3 = intersection(temp1,temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(temp3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
